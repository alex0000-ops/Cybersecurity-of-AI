- Membership inference attacks occur when an attacker manipulates the model’s
  training data in order to cause it to behave in a way that exposes sensitive
  information. [zdroj](https://owasp.org/www-project-machine-learning-security-top-10/docs/ML04_2023-Membership_Inference_Attack)
- But a type of attack called “membership inference” makes it possible to 
  detect the data used to train a machine learning model. In many cases, 
  the attackers can stage membership inference attacks without having 
  access to the machine learning model’s parameters and just by observing 
  its output. Membership inference can cause security and privacy concerns
   in cases where the target model has been trained on sensitive 
  information.
  
  In membership inference attacks, the adversary does not necessarily need
   to have knowledge about the inner parameters of the target machine 
  learning model. Instead, the attacker only knows the model’s algorithm 
  and architecture (e.g., SVM, neural network, etc.) or the service used 
  to create the model. [zdroj](https://bdtechtalks.com/2021/04/23/machine-learning-membership-inference-attacks/)
- machine learning as a service (MaaS)
-